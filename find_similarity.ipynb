{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import statistics\n",
    "from scipy import spatial\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "similarity_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'category_event_topic_vector_nnmf'\n",
    "file = open(filepath, 'rb')\n",
    "category_event_topic_vector = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'e_yrsvp'\n",
    "file = open(filepath, 'rb')\n",
    "event_yrsvp = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category:', 0)\n",
      "('less len:', 10319, ' great len: ', 9957)\n",
      "('less_similarityL', 48908486.602297455, ' less_count:', 53081056)\n",
      "('my_dict:', {'cross_similarity': 0.9526894030874409, 'less_similarity': 0.9213924945708966, 'great_similarity': 0.8954330174781645})\n",
      "('category:', 1)\n",
      "('less len:', 4434, ' great len: ', 2469)\n",
      "('less_similarityL', 9033809.062102644, ' less_count:', 9748320)\n",
      "('my_dict:', {'cross_similarity': 0.9188206447160763, 'less_similarity': 0.9267041974517295, 'great_similarity': 0.8826149793476646})\n",
      "('category:', 2)\n",
      "('less len:', 10637, ' great len: ', 8162)\n",
      "('less_similarityL', 51330095.33893703, ' less_count:', 55973490)\n",
      "('my_dict:', {'cross_similarity': 0.9052058602378802, 'less_similarity': 0.9170429669283983, 'great_similarity': 0.8603687571200382})\n",
      "('category:', 3)\n",
      "('less len:', 1046, ' great len: ', 987)\n",
      "('less_similarityL', 497264.3417206017, ' less_count:', 546535)\n",
      "('my_dict:', {'cross_similarity': 0.9702813005814414, 'less_similarity': 0.9098490338598657, 'great_similarity': 0.923064514975306})\n",
      "('category:', 4)\n",
      "('less len:', 3829, ' great len: ', 3343)\n",
      "('less_similarityL', 6467407.616111163, ' less_count:', 6958315)\n",
      "('my_dict:', {'cross_similarity': 0.9261924504801977, 'less_similarity': 0.9294502499687299, 'great_similarity': 0.8775883516911822})\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "category_wise_attendance_dict = {}\n",
    "for category,event_topic_vector in category_event_topic_vector.items():\n",
    "    print(\"category:\",category)\n",
    "    if category == 24:\n",
    "        continue\n",
    "    category_wise_attendance_dict[category] = []\n",
    "    attendance_list = []\n",
    "    less_attendance_vectors = []\n",
    "    great_attendance_vectors = []\n",
    "    less_similarity = 0.0\n",
    "    less_count = 0\n",
    "    great_similarity = 0.0\n",
    "    great_count = 0\n",
    "    cross_similarity = 0.0\n",
    "    cross_count = 0\n",
    "    for event in event_topic_vector.keys():\n",
    "        try:\n",
    "            attendance_list.append(event_yrsvp[event])\n",
    "        except:\n",
    "            pass\n",
    "    attendance_median = statistics.median(attendance_list)\n",
    "    # print(\"attendance_median:\",attendance_median, \" len  of attendance list\", len(attendance_list))\n",
    "    for event,topic_vector in event_topic_vector.items():\n",
    "        try:\n",
    "            c_attendance = event_yrsvp[event]\n",
    "            temp_dict = {}\n",
    "            temp_dict['vector'] = topic_vector\n",
    "            if c_attendance <= attendance_median:\n",
    "                less_attendance_vectors.append(topic_vector)\n",
    "                temp_dict['attendance'] = 0\n",
    "                \n",
    "            else:\n",
    "                great_attendance_vectors.append(topic_vector)\n",
    "                temp_dict['attendance'] = 0\n",
    "            category_wise_attendance_dict[category].append(temp_dict)\n",
    "        except:\n",
    "            pass\n",
    "    print(\"less len:\",len(less_attendance_vectors), \" great len: \", len(great_attendance_vectors) )\n",
    "    for i in range(len(less_attendance_vectors)):\n",
    "        for j in range(i+1,len(less_attendance_vectors)):\n",
    "            res1 = sum(map(lambda i : i * i, less_attendance_vectors[i])) \n",
    "            res2 = sum(map(lambda i : i * i, less_attendance_vectors[j]))\n",
    "            if res1 == 0 or res2 == 0:\n",
    "                continue;\n",
    "            less_similarity = less_similarity + spatial.distance.cosine(less_attendance_vectors[i], less_attendance_vectors[j])\n",
    "            #if 1 - spatial.distance.cosine(less_attendance_vectors[i], less_attendance_vectors[j]) > 1:\n",
    "                #print 1 - spatial.distance.cosine(less_attendance_vectors[i], less_attendance_vectors[j])\n",
    "            # print 1 - spatial.distance.cosine(less_attendance_vectors[i], less_attendance_vectors[j])\n",
    "            less_count = less_count + 1\n",
    "            \n",
    "    for i in range(len(less_attendance_vectors)):\n",
    "        for j in range(len(great_attendance_vectors)):\n",
    "            res1 = sum(map(lambda i : i * i, less_attendance_vectors[i])) \n",
    "            res2 = sum(map(lambda i : i * i, great_attendance_vectors[j]))\n",
    "            if res1 == 0 or res2 == 0:\n",
    "                continue;\n",
    "            cross_similarity = cross_similarity + spatial.distance.cosine(less_attendance_vectors[i], great_attendance_vectors[j])\n",
    "            # print cross_similarity\n",
    "            cross_count = cross_count + 1\n",
    "            \n",
    "    for i in range(len(great_attendance_vectors)):\n",
    "        for j in range(i+1,len(great_attendance_vectors)):\n",
    "            res1 = sum(map(lambda i : i * i, great_attendance_vectors[i])) \n",
    "            res2 = sum(map(lambda i : i * i, great_attendance_vectors[j]))\n",
    "            if res1 == 0 or res2 == 0:\n",
    "                continue;\n",
    "            great_similarity = great_similarity +  spatial.distance.cosine(great_attendance_vectors[i], great_attendance_vectors[j])\n",
    "            great_count = great_count + 1\n",
    "    \n",
    "    print(\"less_similarityL\",less_similarity,\" less_count:\", less_count)\n",
    "    less_similarity = (less_similarity / float(less_count))\n",
    "    great_similarity = great_similarity / great_count\n",
    "    cross_similarity = cross_similarity / cross_count\n",
    "    my_dict = {}\n",
    "    my_dict[\"less_similarity\"] = less_similarity\n",
    "    my_dict[\"great_similarity\"] = great_similarity\n",
    "    my_dict[\"cross_similarity\"] = cross_similarity\n",
    "    similarity_dict[category] = my_dict\n",
    "    print(\"my_dict:\",my_dict)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'similarity_dict'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(similarity_dict,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category:', 0)\n",
      "('category:', 1)\n",
      "('category:', 2)\n",
      "('category:', 3)\n",
      "('category:', 4)\n"
     ]
    }
   ],
   "source": [
    "category_wise_attendance_dict = {}\n",
    "for category,event_topic_vector in category_event_topic_vector.items():\n",
    "    print(\"category:\",category)\n",
    "    if category == 24:\n",
    "        continue\n",
    "    category_wise_attendance_dict[category] = []\n",
    "    attendance_list = []\n",
    "    less_attendance_vectors = []\n",
    "    great_attendance_vectors = []\n",
    "    less_similarity = 0.0\n",
    "    less_count = 0\n",
    "    great_similarity = 0.0\n",
    "    great_count = 0\n",
    "    cross_similarity = 0.0\n",
    "    cross_count = 0\n",
    "    for event in event_topic_vector.keys():\n",
    "        try:\n",
    "            attendance_list.append(event_yrsvp[event])\n",
    "        except:\n",
    "            pass\n",
    "    attendance_median = statistics.median(attendance_list)\n",
    "    # print(\"attendance_median:\",attendance_median, \" len  of attendance list\", len(attendance_list))\n",
    "    for event,topic_vector in event_topic_vector.items():\n",
    "        try:\n",
    "            c_attendance = event_yrsvp[event]\n",
    "            temp_dict = {}\n",
    "            temp_dict['vector'] = topic_vector\n",
    "            if c_attendance <= attendance_median:\n",
    "                less_attendance_vectors.append(topic_vector)\n",
    "                temp_dict['attendance'] = 0\n",
    "                \n",
    "            else:\n",
    "                great_attendance_vectors.append(topic_vector)\n",
    "                temp_dict['attendance'] = 1\n",
    "            category_wise_attendance_dict[category].append(temp_dict)\n",
    "        except:\n",
    "            pass\n",
    "filename = 'category_wise_attendance_dict'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(category_wise_attendance_dict,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category:', 0)\n",
      "{'cross_similarity': 0.04731059691255912, 'less_similarity': 0.07860750542910344, 'great_similarity': 0.1045669825218355}\n",
      "('category:', 1)\n",
      "{'cross_similarity': 0.08117935528392373, 'less_similarity': 0.0732958025482705, 'great_similarity': 0.11738502065233536}\n",
      "('category:', 2)\n",
      "{'cross_similarity': 0.09479413976211981, 'less_similarity': 0.08295703307160174, 'great_similarity': 0.13963124287996176}\n",
      "('category:', 3)\n",
      "{'cross_similarity': 0.029718699418558647, 'less_similarity': 0.09015096614013429, 'great_similarity': 0.07693548502469405}\n",
      "('category:', 4)\n",
      "{'cross_similarity': 0.07380754951980228, 'less_similarity': 0.07054975003127006, 'great_similarity': 0.12241164830881779}\n",
      "('rcount: ', 2)\n",
      "('tcount: ', 5)\n"
     ]
    }
   ],
   "source": [
    "filepath = 'similarity_dict'\n",
    "file = open(filepath, 'rb')\n",
    "similarityDict= pickle.load(file)\n",
    "tcount = 0\n",
    "rcount = 0\n",
    "for category in similarityDict.keys():\n",
    "    similarityDict[category]['cross_similarity'] = 1 - similarityDict[category]['cross_similarity']\n",
    "    similarityDict[category]['less_similarity'] = 1 - similarityDict[category]['less_similarity']\n",
    "    similarityDict[category]['great_similarity'] = 1 - similarityDict[category]['great_similarity']\n",
    "    if similarityDict[category]['cross_similarity'] < min(similarityDict[category]['less_similarity'],similarityDict[category]['great_similarity']):\n",
    "        rcount += 1\n",
    "    print(\"category:\",category)\n",
    "    print similarityDict[category]\n",
    "    tcount += 1\n",
    "print(\"rcount: \",rcount)\n",
    "print(\"tcount: \",tcount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
